# ETL Climate Insight 

## ğŸ“Œ Deskripsi Proyek

ETL Climate Insight adalah sistem **End-to-End Data Pipeline** untuk mengambil data cuaca, memprosesnya, menyimpannya, dan menampilkannya pada dashboard Streamlit. Seluruh workflow dikelola menggunakan **Apache Airflow** yang berjalan di Docker sehingga user hanya perlu menjalankan **satu perintah**:

```
docker compose up -d
```

Pipeline ini berjalan otomatis menggunakan DAG Airflow untuk melakukan proses:

1. **Extract** â€” Mengambil data wilayah + cuaca dari API publik
2. **Transform** â€” Membersihkan, menstrukturkan, dan menyimpan data dalam direktori `data/`
3. **Load** â€” Menyediakan hasil akhir untuk diakses Streamlit Dashboard
4. **Visualisasi** â€” Dashboard Streamlit menampilkan insight cuaca secara real-time

---

## ğŸ“‚ Struktur Folder
```
ETL-Climate-Insight/
â”‚
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/                â†’ DAG Airflow untuk ETL
â”‚   â”œâ”€â”€ logs/                â†’ Log eksekusi Airflow
â”‚   â””â”€â”€ plugins/             â†’ Airflow plugins (opsional)
â”‚
â”œâ”€â”€ config/                  â†’ File konfigurasi tambahan
â”œâ”€â”€ src/                     â†’ Kode utama ETL (extract / transform / load)
â”œâ”€â”€ data/                    â†’ Output final hasil ETL
â”œâ”€â”€ raw_data/                â†’ Data mentah hasil extract
â”‚
â”œâ”€â”€ dashboard/               â†’ Aplikasi Streamlit visualisasi
â”‚   â””â”€â”€ app.py               â†’ Dashboard utama
â”‚
â”œâ”€â”€ Dockerfile.airflow       â†’ Dockerfile image Airflow
â”œâ”€â”€ Dockerfile.etl           â†’ Dockerfile environment worker ETL
â”œâ”€â”€ Dockerfile.streamlit     â†’ Dockerfile environment Streamlit
â”‚
â”œâ”€â”€ docker-compose.yaml      â†’ Orkestrasi seluruh service
â”œâ”€â”€ requirements.txt         â†’ Dependencies Python
â””â”€â”€ README.md                â†’ File ini
```

---

## ğŸš€ Arsitektur Sistem

```
               +---------------------+
               |     Streamlit       |
               |   (Visualisasi)     |
               +----------+----------+
                          ^
                          |
                        (data/)
                          |
+---------+     +--------+---------+      +--------------------+
| Raw API | --> |    ETL (src/)    | ---> | Airflow Scheduler  |
+---------+     +--------+---------+      +--------------------+
                          ^
                          |
                    +-----+-------+
                    | Airflow DAG |
                    +-------------+
```

Semua komponen berjalan dalam container terpisah yang saling terhubung melalui **Docker Compose**.

---

## âš™ï¸ Komponen Utama

### 1. **Airflow**

Mengelola dan menjalankan pipeline ETL otomatis:

* Menjalankan task Extract
* Menjalankan task Transform
* Menjalankan task Load
* Menjadwalkan pipeline harian

Menggunakan **SequentialExecutor** agar kompatibel di Windows + SQLite.

### 2. **ETL Worker**

Container khusus untuk menjalankan script Python ETL:

* Mengambil API cuaca
* Menyimpan raw_data ke folder `raw_data/`
* Memproses menjadi data final di `data/`

Task Airflow memanggil command Python di dalam container ini.

### 3. **Streamlit Dashboard**

Menampilkan:

* suhu setiap kota
* kelembapan
* kondisi cuaca
* grafik line, bar, dan map menggunakan Plotly

Dashboard otomatis membaca folder `data/` hasil ETL.

---

## ğŸ³ Cara Instalasi & Setup

### 1ï¸âƒ£ **Clone / Download Project**

```
git clone https://github.com/TaqiyudinMiftah/ETL-Climate-Insight
cd ETL-Climate-Insight
```

### 2ï¸âƒ£ **Pastikan Docker sudah terinstall**

Cek dengan:

```
docker --version
docker compose version
```

### 3ï¸âƒ£ Jalankan Semua Service

```
docker compose up -d --build
```

Docker akan menjalankan:

* airflow-init â†’ migrate DB + create user
* airflow-scheduler
* airflow-webserver
* etl-worker
* streamlit-dashboard

### 4ï¸âƒ£ Buka Airflow Web UI

```
http://localhost:8080
```

Login:

* username: `admin`
* password: `admin`

### 5ï¸âƒ£ Buka Dashboard Streamlit

```
http://localhost:8501
```

Dashboard otomatis membaca file output dari hasil ETL.

---

## ğŸ§ª Menjalankan ETL Secara Manual

Di Airflow UI:

1. Cari DAG bernama **etl_climate_insight**
2. Klik **Trigger DAG**
3. Periksa tree/graph untuk melihat status task

Output akan tersimpan di:

* `raw_data/` â†’ data mentah
* `data/` â†’ data siap pakai + dibaca Streamlit

---

## ğŸ›  Perbaikan Error Umum

### â— Airflow tidak bisa start â†’ Database belum di-init

Solusi:

```
docker compose down -v
docker compose up -d --build
```

### â— LocalExecutor tidak cocok di Windows

Sudah diperbaiki â†’ menggunakan SequentialExecutor.

### â— Streamlit error "ModuleNotFoundError"

Pastikan `requirements.txt` seperti berikut:

```
streamlit
pandas
python-dateutil
cryptography
plotly
pyyaml
```

---

